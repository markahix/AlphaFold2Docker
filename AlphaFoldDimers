#!/usr/bin/env python3

#######################
### Library Imports ###
#######################
import os
import sys
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
from Bio import BiopythonDeprecationWarning
warnings.simplefilter(action='ignore', category=BiopythonDeprecationWarning)
from pathlib import Path
from colabfold.download import download_alphafold_params, default_data_dir
from colabfold.utils import setup_logging
from colabfold.batch import get_queries, run, set_model_type
from colabfold.plot import plot_msa_v2
from colabfold.colabfold import plot_protein
import matplotlib.pyplot as plt
import numpy as np
import argparse
from glob import glob as G

############################
### Function Definitions ###
############################
display_images = False
def check(folder):
    if os.path.exists(folder):
        return False
    else:
        return True

def iterative_foldername(jobname):
    # check if directory with jobname exists
    if not check(jobname):
        n = 0
        while not check(f"{jobname}_{n}"): 
            n += 1
        jobname = f"{jobname}_{n}"
    os.makedirs(jobname, exist_ok=True)
    return jobname

def input_features_callback(input_features):
    if display_images:
        print("Attempting to display images")
        plot_msa_v2(input_features)
        plt.show()
        plt.close()

def prediction_callback(protein_obj, length, prediction_result, input_features, mode):
    model_name, relaxed = mode
    if all([not relaxed, display_images]):
        print("Attempting to display images")
        fig = plot_protein(protein_obj, Ls=length, dpi=150)
        plt.show()
        plt.close()

def CompleteJobProcess(JobSettings):
    JobName                      = JobSettings["JOBNAME"]
    Sequence_1                   = JobSettings["SEQUENCE_1"]
    Sequence_2                   = JobSettings["SEQUENCE_2"]
    msa_mode                     = JobSettings["MSA_MODE"]
    pair_mode                    = JobSettings["PAIR_MODE"]
    model_type                   = JobSettings["MODEL_TYPE"]
    num_recycles                 = JobSettings["NUM_RECYCLES"]
    recycle_early_stop_tolerance = JobSettings["RECYCLE_EARLY_STOP_TOLERANCE"]
    relax_max_iterations         = JobSettings["RELAX_MAX_ITERATIONS"]
    pairing_strategy             = JobSettings["PAIRING_STRATEGY"]
    max_msa                      = JobSettings["MAX_MSA"]
    num_seeds                    = JobSettings["NUM_SEEDS"]
    use_dropout                  = JobSettings["USE_DROPOUT"]
    save_all                     = JobSettings["SAVE_ALL"]
    save_recycles                = JobSettings["SAVE_RECYCLES"]
    dpi                          = JobSettings["DPI"]
    display_images               = JobSettings["DISPLAY_IMAGES"]
    
    Sequence_1 = "".join(Sequence_1.split())
    Sequence_2 = "".join(Sequence_2.split())
    if all([Sequence_1.strip() != "",Sequence_2.strip() != "" ]):
        query_sequence = Sequence_1 + ":" + Sequence_2
    else:
        query_sequence = Sequence_1 + Sequence_2
    
    ######################################
    # Generate Fresh Job Name for Folder #
    ######################################
    jobname = iterative_foldername(JobName)
    
    ################
    # Save Queries #
    ################
    queries_path = os.path.join(jobname, "queries.csv")
    with open(queries_path, "w") as text:
      text.write(f"id,sequence\n{jobname},{query_sequence}")
    
    custom_template_path = None
    use_templates = True
    # decide which a3m to use
    if "mmseqs2" in msa_mode:
        a3m_file = os.path.join(jobname,f"{jobname}.a3m")
    
    elif msa_mode == "custom":
        a3m_file = os.path.join(jobname,f"{jobname}.custom.a3m")
        if not os.path.isfile(a3m_file):
            custom_msa_dict = files.upload()
            custom_msa = list(custom_msa_dict.keys())[0]
            header = 0
            import fileinput
            for line in fileinput.FileInput(custom_msa,inplace=1):
                if line.startswith(">"):
                    header = header + 1
                if not line.rstrip():
                    continue
                if line.startswith(">") == False and header == 1:
                    query_sequence = line.rstrip()
                print(line, end='')
            os.rename(custom_msa, a3m_file)
            queries_path=a3m_file
            print(f"moving {custom_msa} to {a3m_file}")
    
    else:
        a3m_file = os.path.join(jobname,f"{jobname}.single_sequence.a3m")
        with open(a3m_file, "w") as text_file:
            text_file.write(">1\n%s" % query_sequence)

    num_recycles = None if num_recycles == "auto" else int(num_recycles)
    recycle_early_stop_tolerance = None if recycle_early_stop_tolerance == "auto" else float(recycle_early_stop_tolerance)
    if max_msa == "auto": 
        max_msa = None
    
    
    result_dir = jobname
    log_filename = os.path.join(jobname,"log.txt")
    if not os.path.isfile(log_filename) or 'logging_setup' not in globals():
      setup_logging(Path(log_filename))
      logging_setup = True
    
    queries, is_complex = get_queries(queries_path)
    model_type = set_model_type(is_complex, model_type)
    
    if "multimer" in model_type and max_msa is not None:
      use_cluster_profile = False
    else:
      use_cluster_profile = True
    
    download_alphafold_params(model_type, Path("."))

    results = run(
        queries=queries,
        result_dir=result_dir,
        use_templates=use_templates,
        custom_template_path=custom_template_path,
        num_relax=0,
        msa_mode=msa_mode,
        model_type=model_type,
        num_models=5,
        num_recycles=num_recycles,
        relax_max_iterations=relax_max_iterations,
        recycle_early_stop_tolerance=recycle_early_stop_tolerance,
        num_seeds=num_seeds,
        use_dropout=use_dropout,
        model_order=[1,2,3,4,5],
        is_complex=is_complex,
        data_dir=Path("."),
        keep_existing_results=False,
        rank_by="auto",
        pair_mode=pair_mode,
        pairing_strategy=pairing_strategy,
        stop_at_score=float(100),
        prediction_callback=prediction_callback,
        dpi=dpi,
        zip_results=False,
        save_all=save_all,
        max_msa=max_msa,
        use_cluster_profile=use_cluster_profile,
        input_features_callback=input_features_callback,
        save_recycles=save_recycles,
        user_agent="colabfold/google-colab-main",
    )
    results_zip = f"{jobname}.result.zip"
    os.system(f"zip -r {results_zip} {jobname}")
    
if __name__ == "__main__":
    JobSettings = {"JOBNAME":"AlphaFold2_Job",
                   "SEQUENCE_1":"ACDEFGHIKLMNPQRSTVWY",
                   "SEQUENCE_2":"ACDEFGHIKLMNPQRSTVWY",
                   "MSA_MODE":"mmseqs2_uniref_env",
                   "PAIR_MODE":"unpaired_paired",
                   "MODEL_TYPE":"auto",
                   "NUM_RECYCLES":3,
                   "RECYCLE_EARLY_STOP_TOLERANCE":"auto",
                   "RELAX_MAX_ITERATIONS":200,
                   "PAIRING_STRATEGY":"greedy",
                   "MAX_MSA":"auto",
                   "NUM_SEEDS":1,
                   "USE_DROPOUT":False,
                   "SAVE_ALL":False,
                   "SAVE_RECYCLES":False,
                   "DPI":300,
                   "DISPLAY_IMAGES":False
                   }
    parser = argparse.ArgumentParser()
    parser.add_argument("-i","--input",dest="input",required=True,help="Input file with necessary information: [jobname, sequence1, sequence2]")
    args = parser.parse_args()
    if not G(args.input):
        print("Input file not found.  Default settings input file generated.")
        with open(args.input,"w") as f:
            for key,val in JobSettings.items():
                f.write(f"{key}:{val}\n")
        quit()
    for line in open(args.input).readlines():   
        [key,val] = line.split(":")
        val = val.strip()
        if type(val) == str:
            if val == "False":
                val = False
            elif val == "True":
                val = True
            elif val.isdigit():
                val = int(val)
            elif val.isnumeric():
                val = float(val)
        JobSettings[key.upper()] = val
    CompleteJobProcess(JobSettings)
    
    
    
    
    
    
